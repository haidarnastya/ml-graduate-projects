{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Haidar_Anastasia_HW7</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Anastasia Haidar\n",
    "<br>\n",
    "Github Username: haidarnastya\n",
    "<br>\n",
    "USC ID: 1163-9833-46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import make_scorer, hamming_loss, accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download the Anuran Calls (MFCCs) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (3445, 26)\n",
      "Test data shape: (3750, 26)\n"
     ]
    }
   ],
   "source": [
    "mfcc_data = pd.read_csv('./data/Frogs_MFCCs.csv')\n",
    "\n",
    "#Choose 70% of the data randomly as the training set. Note Record ID\n",
    "record_id = mfcc_data['RecordID'].unique()\n",
    "np.random.seed(42)\n",
    "training_ids = np.random.choice(record_id, size=int(0.7*len(record_id)), replace=False)\n",
    "\n",
    "training_data = mfcc_data[mfcc_data['RecordID'].isin(training_ids)]\n",
    "test_data = mfcc_data[~mfcc_data['RecordID'].isin(training_ids)]\n",
    "print('Training data shape:', training_data.shape)\n",
    "print('Test data shape:', test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Train a classifier for each label\n",
    "Each instance has three labels: Families, Genus, and Species. Each of the labels\n",
    "has multiple classes. We wish to solve a multi-class and multi-label problem.\n",
    "One of the most important approaches to multi-label classification is to train a\n",
    "classifier for each label (binary relevance). We first try this approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research exact match and hamming score/ loss methods for evaluating multilabel classification and use them in evaluating the classifiers in this problem.\n",
    "\n",
    "Hamming Loss measures the fraction of labels that are incorrectly predicted, accounting for both false positives and false negatives while also being normalized. The Hamming Score, represents the proportion of correctly predicted labels and provides a less strict assessment than exact match. Exact Match (0-1 Loss) evaluates whether all labels for an instance are predicted perfectly, counting any partially incorrect prediction as a failure.\n",
    "\n",
    "https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Train a SVM for each of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM for label: Family\n",
      "C=0.001, Training Accuracy=0.46879535558780844\n",
      "C=0.01, Training Accuracy=0.7866473149492017\n",
      "C=0.1, Training Accuracy=0.9515239477503629\n",
      "C=1, Training Accuracy=0.9851959361393323\n",
      "C=10, Training Accuracy=0.9979680696661829\n",
      "C=100, Training Accuracy=1.0\n",
      "C=1000, Training Accuracy=1.0\n",
      "C=10000, Training Accuracy=1.0\n",
      "C=100000, Training Accuracy=1.0\n",
      "C=1000000, Training Accuracy=1.0\n",
      "Gamma=0.001, Training Accuracy=0.5297532656023222\n",
      "Gamma=0.01, Training Accuracy=0.783744557329463\n",
      "Gamma=0.1, Training Accuracy=0.9210449927431059\n",
      "Gamma=0.5, Training Accuracy=0.9753265602322206\n",
      "Gamma=1.0, Training Accuracy=0.9851959361393323\n",
      "Gamma=2.0, Training Accuracy=0.9939042089985486\n",
      "Gamma=5.0, Training Accuracy=0.9985486211901307\n",
      "Gamma=10.0, Training Accuracy=0.9994194484760522\n",
      "C range: 0.01 - 1000000\n",
      "Gamma range: 0.01 - 10.0\n",
      "{'C': array([1.00000000e-02, 7.74263683e-02, 5.99484250e-01, 4.64158883e+00,\n",
      "       3.59381366e+01, 2.78255940e+02, 2.15443469e+03, 1.66810054e+04,\n",
      "       1.29154967e+05, 1.00000000e+06]), 'gamma': array([ 0.01,  1.12,  2.23,  3.34,  4.45,  5.56,  6.67,  7.78,  8.89,\n",
      "       10.  ])}\n",
      "Cross validating for label: Family\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Best parameters:\n",
      "Best C = 2154.4346900318824\n",
      "Best gamma = 0.01\n",
      "Best cross-validation accuracy = 0.8436828815691652\n",
      "Training SVM for label: Genus\n",
      "C=0.001, Training Accuracy=0.3904208998548621\n",
      "C=0.01, Training Accuracy=0.7285921625544267\n",
      "C=0.1, Training Accuracy=0.9262699564586357\n",
      "C=1, Training Accuracy=0.9863570391872278\n",
      "C=10, Training Accuracy=0.9988388969521045\n",
      "C=100, Training Accuracy=1.0\n",
      "C=1000, Training Accuracy=1.0\n",
      "C=10000, Training Accuracy=1.0\n",
      "C=100000, Training Accuracy=1.0\n",
      "C=1000000, Training Accuracy=1.0\n",
      "Gamma=0.001, Training Accuracy=0.44034833091436865\n",
      "Gamma=0.01, Training Accuracy=0.7968069666182874\n",
      "Gamma=0.1, Training Accuracy=0.9137880986937591\n",
      "Gamma=0.5, Training Accuracy=0.974455732946299\n",
      "Gamma=1.0, Training Accuracy=0.9863570391872278\n",
      "Gamma=2.0, Training Accuracy=0.9947750362844703\n",
      "Gamma=5.0, Training Accuracy=0.997677793904209\n",
      "Gamma=10.0, Training Accuracy=0.9991291727140784\n",
      "C range: 0.01 - 1000000\n",
      "Gamma range: 0.01 - 10.0\n",
      "{'C': array([1.00000000e-02, 7.74263683e-02, 5.99484250e-01, 4.64158883e+00,\n",
      "       3.59381366e+01, 2.78255940e+02, 2.15443469e+03, 1.66810054e+04,\n",
      "       1.29154967e+05, 1.00000000e+06]), 'gamma': array([ 0.01,  1.12,  2.23,  3.34,  4.45,  5.56,  6.67,  7.78,  8.89,\n",
      "       10.  ])}\n",
      "Cross validating for label: Genus\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Best parameters:\n",
      "Best C = 35.93813663804626\n",
      "Best gamma = 0.01\n",
      "Best cross-validation accuracy = 0.8204650042274236\n",
      "Training SVM for label: Species\n",
      "C=0.001, Training Accuracy=0.3097242380261248\n",
      "C=0.01, Training Accuracy=0.6644412191582003\n",
      "C=0.1, Training Accuracy=0.9349782293178519\n",
      "C=1, Training Accuracy=0.9878084179970973\n",
      "C=10, Training Accuracy=0.9985486211901307\n",
      "C=100, Training Accuracy=1.0\n",
      "C=1000, Training Accuracy=1.0\n",
      "C=10000, Training Accuracy=1.0\n",
      "C=100000, Training Accuracy=1.0\n",
      "C=1000000, Training Accuracy=1.0\n",
      "Gamma=0.001, Training Accuracy=0.3143686502177068\n",
      "Gamma=0.01, Training Accuracy=0.8063860667634253\n",
      "Gamma=0.1, Training Accuracy=0.9373004354136429\n",
      "Gamma=0.5, Training Accuracy=0.9785195936139333\n",
      "Gamma=1.0, Training Accuracy=0.9878084179970973\n",
      "Gamma=2.0, Training Accuracy=0.9944847605224963\n",
      "Gamma=5.0, Training Accuracy=0.9979680696661829\n",
      "Gamma=10.0, Training Accuracy=0.9997097242380262\n",
      "C range: 0.1 - 1000000\n",
      "Gamma range: 0.01 - 10.0\n",
      "{'C': array([1.00000000e-01, 5.99484250e-01, 3.59381366e+00, 2.15443469e+01,\n",
      "       1.29154967e+02, 7.74263683e+02, 4.64158883e+03, 2.78255940e+04,\n",
      "       1.66810054e+05, 1.00000000e+06]), 'gamma': array([ 0.01,  1.12,  2.23,  3.34,  4.45,  5.56,  6.67,  7.78,  8.89,\n",
      "       10.  ])}\n",
      "Cross validating for label: Species\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Best parameters:\n",
      "Best C = 21.544346900318846\n",
      "Best gamma = 0.01\n",
      "Best cross-validation accuracy = 0.805363972317851\n",
      "Results following Cross Validation:\n",
      "Label: Family, Best C: 2154.4346900318824, Best gamma: 0.01, CV Accuracy: 0.8436828815691652\n",
      "Label: Genus, Best C: 35.93813663804626, Best gamma: 0.01, CV Accuracy: 0.8204650042274236\n",
      "Label: Species, Best C: 21.544346900318846, Best gamma: 0.01, CV Accuracy: 0.805363972317851\n",
      "Test Set Results:\n",
      "Label: Family, Test Error: 0.11386666666666667\n",
      "Label: Genus, Test Error: 0.13680000000000003\n",
      "Label: Species, Test Error: 0.13546666666666662\n"
     ]
    }
   ],
   "source": [
    "#Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. \n",
    "#Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation.\n",
    "\n",
    "###RAW ATTRIBUTES###\n",
    "feature_cols = [col for col in training_data.columns if col.startswith('MFCCs_')]\n",
    "x_train = training_data[feature_cols].values\n",
    "x_test = test_data[feature_cols].values\n",
    "\n",
    "\n",
    "#get record ids for grouped cross validation\n",
    "training_groups = training_data['RecordID'].values\n",
    "test_groups = test_data['RecordID'].values\n",
    "\n",
    "#select label to train on\n",
    "labels = ['Family', 'Genus', 'Species']\n",
    "results = {}\n",
    "\n",
    "#loop through each label\n",
    "for label in labels:\n",
    "    y_train = training_data[label].values\n",
    "    y_test = test_data[label].values\n",
    "    print(\"Training SVM for label:\", label)\n",
    "\n",
    "    ### (1) FIND PARAMETER RANGES FOR MODEL ###\n",
    "    accuracy_threshold = 0.70\n",
    "\n",
    "    C_test_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "    valid_C = []\n",
    "    #test c values (gamma = 1.0)\n",
    "    for C in C_test_values:\n",
    "        svm_model = SVC(kernel = 'rbf', C=C, gamma=1.0, random_state=42)\n",
    "        svm_model.fit(x_train, y_train)\n",
    "        training_accuracy = svm_model.score(x_train, y_train)\n",
    "        print(f\"C={C}, Training Accuracy={training_accuracy}\")\n",
    "        if training_accuracy >= accuracy_threshold:\n",
    "            valid_C.append(C)\n",
    "\n",
    "    #test gamma values\n",
    "    gamma_test_values = [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "    valid_gamma = []\n",
    "\n",
    "    for gamma in gamma_test_values:\n",
    "        svm_model = SVC(kernel='rbf', C=1.0, gamma=gamma, random_state=42)\n",
    "        svm_model.fit(x_train, y_train)\n",
    "        training_accuracy = svm_model.score(x_train, y_train)\n",
    "        print(f\"Gamma={gamma}, Training Accuracy={training_accuracy}\")\n",
    "        if training_accuracy >= accuracy_threshold:\n",
    "            valid_gamma.append(gamma)\n",
    "\n",
    "    #finalize gamma and C ranges\n",
    "    C_min, C_max = min(valid_C), max(valid_C)\n",
    "    gamma_min, gamma_max = min(valid_gamma), max(valid_gamma)\n",
    "    print ('C range:', C_min, '-', C_max)\n",
    "    print ('Gamma range:', gamma_min, '-', gamma_max)\n",
    "\n",
    "    ###(2) CROSS VALIDATION FOR BEST PARAMS###\n",
    "    n_points = 10\n",
    "\n",
    "    #for C use log spacing\n",
    "    #for gamma use linear spacing\n",
    "    log_C_min = np.log10(C_min)\n",
    "    log_C_max = np.log10(C_max)\n",
    "    C_values = np.logspace(log_C_min, log_C_max, n_points)\n",
    "    gamma_values = np.linspace(gamma_min, gamma_max, n_points)\n",
    "\n",
    "    param_grid = {'C': C_values, 'gamma': gamma_values}\n",
    "    print(param_grid)\n",
    "\n",
    "    print('Cross validating for label:', label)\n",
    "    n_folds = 10\n",
    "    gkf = GroupKFold(n_splits=n_folds)\n",
    "\n",
    "    svm_cv = SVC(kernel='rbf', decision_function_shape='ovr', random_state=42)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=svm_cv, param_grid=param_grid, scoring='accuracy', cv=gkf, n_jobs=-1, verbose=2)\n",
    "\n",
    "    #fit grid search with the grouped recordIDs\n",
    "    grid_search.fit(x_train, y_train, groups=training_groups)\n",
    "\n",
    "    print('Best parameters:')\n",
    "    print('Best C =', grid_search.best_params_['C'])\n",
    "    print('Best gamma =', grid_search.best_params_['gamma'])\n",
    "    print('Best cross-validation accuracy =', grid_search.best_score_)\n",
    "\n",
    "    #get best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    #store results\n",
    "    results[label] = {'best_C': grid_search.best_params_['C'], 'best_C': grid_search.best_params_['C'], 'best_gamma': grid_search.best_params_['gamma'], 'cv_accuracy': grid_search.best_score_, 'model': best_model}\n",
    "\n",
    "print('Results following Cross Validation:')\n",
    "for label, res in results.items():\n",
    "    print(f\"Label: {label}, Best C: {res['best_C']}, Best gamma: {res['best_gamma']}, CV Accuracy: {res['cv_accuracy']}\")\n",
    "\n",
    "###(3) USE BEST MODEL ON TEST SET PREDICTION ###\n",
    "#print test error result for each label\n",
    "print('Test Set Results:')\n",
    "for label, res in results.items():\n",
    "    best_model = res['model']\n",
    "    y_test = test_data[label].values\n",
    "    y_pred = best_model.predict(x_test)\n",
    "    test_err = 1 - accuracy_score(y_test, y_pred)\n",
    "    print(f\"Label: {label}, Test Error: {test_err}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeat 1(b)ii with L1-penalized SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training L1 SVM for label: Family\n",
      "C=0.001, Training Accuracy=0.7822931785195936\n",
      "C=0.01, Training Accuracy=0.8827285921625544\n",
      "C=0.1, Training Accuracy=0.9027576197387518\n",
      "C=1, Training Accuracy=0.9123367198838896\n",
      "C=10, Training Accuracy=0.9134978229317852\n",
      "C=100, Training Accuracy=0.9134978229317852\n",
      "C=1000, Training Accuracy=0.9134978229317852\n",
      "C=10000, Training Accuracy=0.9134978229317852\n",
      "C=100000, Training Accuracy=0.9134978229317852\n",
      "C=1000000, Training Accuracy=0.9134978229317852\n",
      "C range: 0.001 - 1000000\n",
      "{'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04,\n",
      "       1.e+05, 1.e+06])}\n",
      "Cross validating for label: Family\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Best parameters:\n",
      "Best C = 100.0\n",
      "Best cross-validation accuracy = 0.8026461132481291\n",
      "Training L1 SVM for label: Genus\n",
      "C=0.001, Training Accuracy=0.6862119013062409\n",
      "C=0.01, Training Accuracy=0.8844702467343977\n",
      "C=0.1, Training Accuracy=0.939622641509434\n",
      "C=1, Training Accuracy=0.9416545718432511\n",
      "C=10, Training Accuracy=0.941944847605225\n",
      "C=100, Training Accuracy=0.9425253991291728\n",
      "C=1000, Training Accuracy=0.9425253991291728\n",
      "C=10000, Training Accuracy=0.9425253991291728\n",
      "C=100000, Training Accuracy=0.9425253991291728\n",
      "C=1000000, Training Accuracy=0.9425253991291728\n",
      "C range: 0.01 - 1000000\n",
      "{'C': array([1.00000000e-02, 7.74263683e-02, 5.99484250e-01, 4.64158883e+00,\n",
      "       3.59381366e+01, 2.78255940e+02, 2.15443469e+03, 1.66810054e+04,\n",
      "       1.29154967e+05, 1.00000000e+06])}\n",
      "Cross validating for label: Genus\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Best parameters:\n",
      "Best C = 0.5994842503189409\n",
      "Best cross-validation accuracy = 0.8355214814844307\n",
      "Training L1 SVM for label: Species\n",
      "C=0.001, Training Accuracy=0.6319303338171263\n",
      "C=0.01, Training Accuracy=0.8896952104499274\n",
      "C=0.1, Training Accuracy=0.9497822931785196\n",
      "C=1, Training Accuracy=0.9608127721335269\n",
      "C=10, Training Accuracy=0.9616835994194485\n",
      "C=100, Training Accuracy=0.9608127721335269\n",
      "C=1000, Training Accuracy=0.9611030478955007\n",
      "C=10000, Training Accuracy=0.9611030478955007\n",
      "C=100000, Training Accuracy=0.9611030478955007\n",
      "C=1000000, Training Accuracy=0.9611030478955007\n",
      "C range: 0.01 - 1000000\n",
      "{'C': array([1.00000000e-02, 7.74263683e-02, 5.99484250e-01, 4.64158883e+00,\n",
      "       3.59381366e+01, 2.78255940e+02, 2.15443469e+03, 1.66810054e+04,\n",
      "       1.29154967e+05, 1.00000000e+06])}\n",
      "Cross validating for label: Species\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Best parameters:\n",
      "Best C = 0.5994842503189409\n",
      "Best cross-validation accuracy = 0.8230752220926654\n",
      "Results following Cross Validation:\n",
      "Label: Family, Best C: 100.0, CV Accuracy: 0.8026461132481291\n",
      "Label: Genus, Best C: 0.5994842503189409, CV Accuracy: 0.8355214814844307\n",
      "Label: Species, Best C: 0.5994842503189409, CV Accuracy: 0.8230752220926654\n",
      "Test Set Results:\n",
      "Label: Family, Test Error: 1.0\n",
      "Label: Genus, Test Error: 1.0\n",
      "Label: Species, Test Error: 0.13546666666666662\n"
     ]
    }
   ],
   "source": [
    "#Repeat 1(b)ii with L1-penalized SVMs.\n",
    "#Remember to standardize the attributes. \n",
    "#Determine the weight of the SVM penalty using 10 fold cross validation.\n",
    "\n",
    "###STANDARDIZE ATTRIBUTES###\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "#get record ids for grouped cross validation\n",
    "training_groups = training_data['RecordID'].values\n",
    "test_groups = test_data['RecordID'].values\n",
    "\n",
    "#select label to train on\n",
    "labels = ['Family', 'Genus', 'Species']\n",
    "results_l1 = {}\n",
    "\n",
    "#loop through each label\n",
    "for label in labels:\n",
    "    y_train = training_data[label].values\n",
    "    y_test = test_data[label].values\n",
    "    print(\"Training L1 SVM for label:\", label)\n",
    "\n",
    "    ### (1) FIND PARAMETER RANGES FOR MODEL ###\n",
    "    accuracy_threshold = 0.70\n",
    "\n",
    "    C_test_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "    valid_C = []\n",
    "    #test c values (gamma = 1.0)\n",
    "    for C in C_test_values:\n",
    "        l1_svm_model = LinearSVC(penalty = 'l1', dual=False, C=C, max_iter=10000, random_state=42)\n",
    "        l1_svm_model.fit(x_train_scaled, y_train)\n",
    "        training_accuracy = l1_svm_model.score(x_train_scaled, y_train)\n",
    "        print(f\"C={C}, Training Accuracy={training_accuracy}\")\n",
    "        if training_accuracy >= accuracy_threshold:\n",
    "            valid_C.append(C)\n",
    "\n",
    "    #finalize C range\n",
    "    C_min, C_max = min(valid_C), max(valid_C)\n",
    "    print ('C range:', C_min, '-', C_max)\n",
    "\n",
    "    ###(2) CROSS VALIDATION FOR BEST PARAMS###\n",
    "    n_points = 10\n",
    "\n",
    "    #for C use log spacing\n",
    "    #for gamma use linear spacing\n",
    "    log_C_min = np.log10(C_min)\n",
    "    log_C_max = np.log10(C_max)\n",
    "    C_values = np.logspace(log_C_min, log_C_max, n_points)\n",
    "    gamma_values = np.linspace(gamma_min, gamma_max, n_points)\n",
    "\n",
    "    param_grid = {'C': C_values}\n",
    "    print(param_grid)\n",
    "\n",
    "    print('Cross validating for label:', label)\n",
    "    n_folds = 10\n",
    "    l1_gkf = GroupKFold(n_splits=n_folds)\n",
    "\n",
    "    l1_svm_cv = LinearSVC(penalty='l1', dual=False, max_iter=10000, random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=l1_svm_cv, param_grid=param_grid, scoring='accuracy', cv=l1_gkf, n_jobs=-1, verbose=2)\n",
    "\n",
    "    #fit grid search with the grouped recordIDs\n",
    "    grid_search.fit(x_train_scaled, y_train, groups=training_groups)\n",
    "\n",
    "    print('Best parameters:')\n",
    "    print('Best C =', grid_search.best_params_['C'])\n",
    "    print('Best cross-validation accuracy =', grid_search.best_score_)\n",
    "\n",
    "    #get best model\n",
    "    l1_best_model = grid_search.best_estimator_\n",
    "\n",
    "    #store results\n",
    "    results[label] = {'best_C': grid_search.best_params_['C'], 'best_C': grid_search.best_params_['C'], 'cv_accuracy': grid_search.best_score_, 'model': best_model}\n",
    "\n",
    "print('Results following Cross Validation:')\n",
    "for label, res in results.items():\n",
    "    print(f\"Label: {label}, Best C: {res['best_C']}, CV Accuracy: {res['cv_accuracy']}\")\n",
    "\n",
    "###(3) USE BEST MODEL ON TEST SET PREDICTION ###\n",
    "#print l1 test error result for each label\n",
    "print('Test Set Results:')\n",
    "for label, res in results.items():\n",
    "    l1_best_model = res['model']\n",
    "    y_test = test_data[label].values\n",
    "    y_pred_l1 = l1_best_model.predict(x_test)\n",
    "    test_err_l1 = 1 - accuracy_score(y_test, y_pred_l1)\n",
    "    print(f\"Label: {label}, Test Error: {test_err_l1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) Repeat 1(b)iii by using SMOTE or any other method for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM with SMOTE for label: Family\n",
      "Testing C values for label: Family\n",
      "C range: 0.001 - 1000000\n",
      "Performing 10-fold Cross Validation for label: Family\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Best Params for {label}:\n",
      "Best C = 1.0\n",
      "Best Cross validation accuracy = 0.9092879256965943\n",
      "Label: Family, Best C: 1.0, CV Accuracy: 0.9092879256965943, Test Error: 0.13280000000000003\n",
      "Training SVM with SMOTE for label: Genus\n",
      "Testing C values for label: Genus\n",
      "C range: 0.001 - 1000000\n",
      "Performing 10-fold Cross Validation for label: Genus\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Best Params for {label}:\n",
      "Best C = 10.0\n",
      "Best Cross validation accuracy = 0.9516728624535317\n",
      "Label: Family, Best C: 1.0, CV Accuracy: 0.9092879256965943, Test Error: 0.13280000000000003\n",
      "Label: Genus, Best C: 10.0, CV Accuracy: 0.9516728624535317, Test Error: 0.16133333333333333\n",
      "Training SVM with SMOTE for label: Species\n",
      "Testing C values for label: Species\n",
      "C range: 0.001 - 1000000\n",
      "Performing 10-fold Cross Validation for label: Species\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Best Params for {label}:\n",
      "Best C = 100.0\n",
      "Best Cross validation accuracy = 0.9712277413308342\n",
      "Label: Family, Best C: 1.0, CV Accuracy: 0.9092879256965943, Test Error: 0.13280000000000003\n",
      "Label: Genus, Best C: 10.0, CV Accuracy: 0.9516728624535317, Test Error: 0.16133333333333333\n",
      "Label: Species, Best C: 100.0, CV Accuracy: 0.9712277413308342, Test Error: 0.15946666666666665\n"
     ]
    }
   ],
   "source": [
    "#Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. \n",
    "#Report your conclusions about the classifiers you trained.\n",
    "\n",
    "#labels to train on\n",
    "labels = ['Family', 'Genus', 'Species']\n",
    "results_smote = {}\n",
    "\n",
    "#loop through each label\n",
    "for label in labels:\n",
    "    y_train = training_data[label].values\n",
    "    y_test = test_data[label].values\n",
    "    print(\"Training SVM with SMOTE for label:\", label)\n",
    "\n",
    "    ###(1) APPLY SMOTE ###\n",
    "    #apply SMOTE to TRAINING DATA only\n",
    "    smote = SMOTE(random_state=42)\n",
    "    x_train_smote, y_train_smote = smote.fit_resample(x_train_scaled, y_train)\n",
    "\n",
    "    #find c param range\n",
    "    accuracy_threshold = 0.70\n",
    "    C_test_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "    valid_C = []\n",
    "    print('Testing C values for label:', label)\n",
    "    for C in C_test_values:\n",
    "        svm_smote_model = LinearSVC(penalty='l1', dual=False, C=C, max_iter=10000, random_state=42)\n",
    "        svm_smote_model.fit(x_train_smote, y_train_smote)\n",
    "        training_acc_smote = svm_smote_model.score(x_train_smote, y_train_smote)\n",
    "        if training_acc_smote >= accuracy_threshold:\n",
    "            valid_C.append(C)\n",
    "    \n",
    "    #finalize C range\n",
    "    C_min, C_max = min(valid_C), max(valid_C)\n",
    "    print ('C range:', C_min, '-', C_max)\n",
    "\n",
    "    ###(2) CROSS VALIDATION FOR BEST PARAMS###\n",
    "    n_points = 10\n",
    "    #log spacing for C\n",
    "    log_C_min = np.log10(C_min)\n",
    "    log_C_max = np.log10(C_max)\n",
    "    C_values = np.logspace(log_C_min, log_C_max, n_points)\n",
    "\n",
    "    params = {'C': C_values}\n",
    "    print('Performing 10-fold Cross Validation for label:', label)\n",
    "    n_folds = 10\n",
    "\n",
    "    svm_smote_cv = LinearSVC(penalty='l1', dual=False, max_iter=10000, random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=svm_smote_cv, param_grid=params, scoring='accuracy', cv=n_folds, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "    print('Best Params for {label}:')\n",
    "    print('Best C =', grid_search.best_params_['C'])\n",
    "    print('Best Cross validation accuracy =', grid_search.best_score_)\n",
    "\n",
    "    #get best model\n",
    "    smote_best_model = grid_search.best_estimator_\n",
    "\n",
    "    ###(3) EVALUATE ON TEST SET (NO SMOTE ON TEST)###\n",
    "    y_pred_smote = smote_best_model.predict(x_test_scaled)\n",
    "    test_err_smote = 1 - accuracy_score(y_test, y_pred_smote)\n",
    "\n",
    "    #build results dictionary\n",
    "    results_smote[label] = {'best_C': grid_search.best_params_['C'],\n",
    "                            'cv_accuracy': grid_search.best_score_,\n",
    "                            'test_error': test_err_smote,\n",
    "                            'model': smote_best_model}\n",
    "    for label, res in results_smote.items():\n",
    "     print(f\"Label: {label}, Best C: {res['best_C']}, CV Accuracy: {res['cv_accuracy']}, Test Error: {res['test_error']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Practice: Study the Classifier Chain method and apply it to the above\n",
    "problem.\n",
    "Extra Practice: Research how confusion matrices, precision, recall, ROC,\n",
    "and AUC are defined for multi-label classification and compute them for the\n",
    "classifiers you trained in above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set\n",
    "Monte-Carlo Simulation: Perform the following procedures 50 times, and report\n",
    "the average and standard deviation of the 50 Hamming Distances that you calculate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Use k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 50 Monte Carlo simulations\n",
      "Simulation 1: Best k = 3\n",
      "Simulation 2: Best k = 3\n",
      "Simulation 3: Best k = 3\n",
      "Simulation 4: Best k = 3\n",
      "Simulation 5: Best k = 3\n",
      "Simulation 6: Best k = 3\n",
      "Simulation 7: Best k = 3\n",
      "Simulation 8: Best k = 3\n",
      "Simulation 9: Best k = 4\n",
      "Simulation 10: Best k = 3\n",
      "Simulation 11: Best k = 4\n",
      "Simulation 12: Best k = 3\n",
      "Simulation 13: Best k = 3\n",
      "Simulation 14: Best k = 3\n",
      "Simulation 15: Best k = 3\n",
      "Simulation 16: Best k = 3\n",
      "Simulation 17: Best k = 3\n",
      "Simulation 18: Best k = 3\n",
      "Simulation 19: Best k = 3\n",
      "Simulation 20: Best k = 3\n",
      "Simulation 21: Best k = 4\n",
      "Simulation 22: Best k = 3\n",
      "Simulation 23: Best k = 4\n",
      "Simulation 24: Best k = 3\n",
      "Simulation 25: Best k = 3\n",
      "Simulation 26: Best k = 6\n",
      "Simulation 27: Best k = 3\n",
      "Simulation 28: Best k = 4\n",
      "Simulation 29: Best k = 3\n",
      "Simulation 30: Best k = 3\n",
      "Simulation 31: Best k = 3\n",
      "Simulation 32: Best k = 4\n",
      "Simulation 33: Best k = 3\n",
      "Simulation 34: Best k = 4\n",
      "Simulation 35: Best k = 3\n",
      "Simulation 36: Best k = 4\n",
      "Simulation 37: Best k = 4\n",
      "Simulation 38: Best k = 3\n",
      "Simulation 39: Best k = 3\n",
      "Simulation 40: Best k = 3\n",
      "Simulation 41: Best k = 3\n",
      "Simulation 42: Best k = 4\n",
      "Simulation 43: Best k = 4\n",
      "Simulation 44: Best k = 3\n",
      "Simulation 45: Best k = 3\n",
      "Simulation 46: Best k = 3\n",
      "Simulation 47: Best k = 4\n",
      "Simulation 48: Best k = 3\n",
      "Simulation 49: Best k = 3\n",
      "Simulation 50: Best k = 3\n",
      "Best k values from all 50 simulations:\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 6, 3, 4, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 4, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "#Use k-means clustering on the whole Anuran Calls (MFCCs) Data Set (do not split the data into train and test, \n",
    "#as we are not performing supervised learning in this exercise). \n",
    "#Choose k={1; 2... 50} automatically based on one of the methods provided in the slides \n",
    "#(CH or Gap Statistics or scree plots or Silhouettes) or any other method you know.\n",
    "\n",
    "#use full data set\n",
    "mfcc_data = pd.read_csv('./data/Frogs_MFCCs.csv')\n",
    "\n",
    "#extract features\n",
    "feature_cols = [col for col in mfcc_data.columns if col.startswith('MFCCs_')]\n",
    "x_data = mfcc_data[feature_cols].values\n",
    "\n",
    "#standardize\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x_data)\n",
    "\n",
    "###(1) MONTE CARLO SIMULATION###\n",
    "#k values to iterate over\n",
    "k_values = range(2, 51)\n",
    "n_simulations = 50\n",
    "best_ks = []\n",
    "\n",
    "print('Performing 50 Monte Carlo simulations')\n",
    "for sim in range(n_simulations):\n",
    "    silhouette_scores = []\n",
    "\n",
    "    ###(2) FIND BEST K FOR EACH SIMULATION###\n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=sim, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(x_scaled)\n",
    "        sil_score = silhouette_score(x_scaled, cluster_labels)\n",
    "        silhouette_scores.append(sil_score)\n",
    "\n",
    "    #best k for this simulation\n",
    "    best_k = k_values[np.argmax(silhouette_scores)]\n",
    "    best_ks.append(best_k)\n",
    "\n",
    "    print(f'Simulation {sim+1}: Best k = {best_k}')\n",
    "\n",
    "print('Best k values from all 50 simulations:')\n",
    "print(best_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Determine which family is the majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining majority labels for best k from each simulation\n",
      "Simulation 1: Assigned majority labels for k = 3\n",
      "Simulation 2: Assigned majority labels for k = 3\n",
      "Simulation 3: Assigned majority labels for k = 3\n",
      "Simulation 4: Assigned majority labels for k = 3\n",
      "Simulation 5: Assigned majority labels for k = 3\n",
      "Simulation 6: Assigned majority labels for k = 3\n",
      "Simulation 7: Assigned majority labels for k = 3\n",
      "Simulation 8: Assigned majority labels for k = 3\n",
      "Simulation 9: Assigned majority labels for k = 4\n",
      "Simulation 10: Assigned majority labels for k = 3\n",
      "Simulation 11: Assigned majority labels for k = 4\n",
      "Simulation 12: Assigned majority labels for k = 3\n",
      "Simulation 13: Assigned majority labels for k = 3\n",
      "Simulation 14: Assigned majority labels for k = 3\n",
      "Simulation 15: Assigned majority labels for k = 3\n",
      "Simulation 16: Assigned majority labels for k = 3\n",
      "Simulation 17: Assigned majority labels for k = 3\n",
      "Simulation 18: Assigned majority labels for k = 3\n",
      "Simulation 19: Assigned majority labels for k = 3\n",
      "Simulation 20: Assigned majority labels for k = 3\n",
      "Simulation 21: Assigned majority labels for k = 4\n",
      "Simulation 22: Assigned majority labels for k = 3\n",
      "Simulation 23: Assigned majority labels for k = 4\n",
      "Simulation 24: Assigned majority labels for k = 3\n",
      "Simulation 25: Assigned majority labels for k = 3\n",
      "Simulation 26: Assigned majority labels for k = 6\n",
      "Simulation 27: Assigned majority labels for k = 3\n",
      "Simulation 28: Assigned majority labels for k = 4\n",
      "Simulation 29: Assigned majority labels for k = 3\n",
      "Simulation 30: Assigned majority labels for k = 3\n",
      "Simulation 31: Assigned majority labels for k = 3\n",
      "Simulation 32: Assigned majority labels for k = 4\n",
      "Simulation 33: Assigned majority labels for k = 3\n",
      "Simulation 34: Assigned majority labels for k = 4\n",
      "Simulation 35: Assigned majority labels for k = 3\n",
      "Simulation 36: Assigned majority labels for k = 4\n",
      "Simulation 37: Assigned majority labels for k = 4\n",
      "Simulation 38: Assigned majority labels for k = 3\n",
      "Simulation 39: Assigned majority labels for k = 3\n",
      "Simulation 40: Assigned majority labels for k = 3\n",
      "Simulation 41: Assigned majority labels for k = 3\n",
      "Simulation 42: Assigned majority labels for k = 4\n",
      "Simulation 43: Assigned majority labels for k = 4\n",
      "Simulation 44: Assigned majority labels for k = 3\n",
      "Simulation 45: Assigned majority labels for k = 3\n",
      "Simulation 46: Assigned majority labels for k = 3\n",
      "Simulation 47: Assigned majority labels for k = 4\n",
      "Simulation 48: Assigned majority labels for k = 3\n",
      "Simulation 49: Assigned majority labels for k = 3\n",
      "Simulation 50: Assigned majority labels for k = 3\n"
     ]
    }
   ],
   "source": [
    "#determine majority labels\n",
    "#extract true labels\n",
    "family = mfcc_data['Family'].values\n",
    "genus = mfcc_data['Genus'].values\n",
    "species = mfcc_data['Species'].values\n",
    "\n",
    "#store labels form each simulation\n",
    "pred_family = []\n",
    "pred_genus = []\n",
    "pred_species = []\n",
    "\n",
    "print('Determining majority labels for best k from each simulation')\n",
    "for sim in range(n_simulations):\n",
    "    best_k = best_ks[sim]\n",
    "\n",
    "    #run kmeans with best k\n",
    "    kmeans = KMeans(n_clusters=best_k, random_state=sim, n_init=10)\n",
    "    cluster_assignment = kmeans.fit_predict(x_scaled)\n",
    "\n",
    "    #predictied arrays\n",
    "    pred_family_label = np.empty(family.shape, dtype=object)\n",
    "    pred_genus_label = np.empty(genus.shape, dtype=object)\n",
    "    pred_species_label = np.empty(species.shape, dtype=object)\n",
    "\n",
    "    #for each cluster, determine majority label\n",
    "    for cluster_id in range(best_k):\n",
    "        idx = np.where(cluster_assignment == cluster_id)[0]\n",
    "\n",
    "        if len(idx) == 0:\n",
    "            #for empty cluster, assign None\n",
    "            pred_family_label[idx] = None\n",
    "            pred_genus_label[idx] = None\n",
    "            pred_species_label[idx] = None\n",
    "        else:\n",
    "            #majority vote for family\n",
    "            majority_family = pd.Series(family[idx]).mode()[0]\n",
    "            pred_family_label[idx] = majority_family\n",
    "\n",
    "            #majority vote for genus\n",
    "            majority_genus = pd.Series(genus[idx]).mode()[0]\n",
    "            pred_genus_label[idx] = majority_genus\n",
    "\n",
    "            #majority vote for species\n",
    "            majority_species = pd.Series(species[idx]).mode()[0]\n",
    "            pred_species_label[idx] = majority_species\n",
    "    \n",
    "    #results\n",
    "    pred_family.append(np.array(pred_family_label, dtype=object))\n",
    "    pred_genus.append(np.array(pred_genus_label, dtype=object))\n",
    "    pred_species.append(np.array(pred_species_label, dtype=object))\n",
    "\n",
    "    print(f'Simulation {sim+1}: Assigned majority labels for k = {best_k}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Calculate the average Hamming distance, Hamming score, and Hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Hamming distances\n",
      "Family:\n",
      "Hamming Distance: Mean = 1580.0600, Std = 167.4194\n",
      "  Hamming Score:    Mean = 0.7804, Std = 0.0233\n",
      "  Hamming Loss:     Mean = 0.2196, Std = 0.0233\n",
      "\n",
      "Genus:\n",
      "  Hamming Distance: Mean = 2060.5, Std = 165.5\n",
      "  Hamming Score:    Mean = 0.7136, Std = 0.0230\n",
      "  Hamming Loss:     Mean = 0.2864, Std = 0.0230\n",
      "\n",
      "Species:\n",
      "  Hamming Distance: Mean = 2152.7, Std = 174.9\n",
      "  Hamming Score:    Mean = 0.7008, Std = 0.0243\n",
      "  Hamming Loss:     Mean = 0.2992, Std = 0.0243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now for each cluster you have a majority label triplet (family, genus, species).\n",
    "#Calculate the average Hamming distance, Hamming score, and Hamming loss\n",
    "#between the true labels and the labels assigned by clusters.\n",
    "\n",
    "#store lists of metrics per simulation\n",
    "hamming_loss_family = []\n",
    "hamming_score_family =[]\n",
    "hamming_distance_family = []\n",
    "\n",
    "hamming_loss_genus =[]\n",
    "hamming_score_genus =[]\n",
    "hamming_distance_genus = []\n",
    "\n",
    "hamming_loss_species = []\n",
    "hamming_score_species = []\n",
    "hamming_distance_species = []\n",
    "\n",
    "print('Calculating Hamming distances')\n",
    "\n",
    "for sim in range(n_simulations):\n",
    "    pred_family_ham = pred_family[sim]\n",
    "    pred_genus_ham = pred_genus[sim]\n",
    "    pred_species_ham = pred_species[sim]\n",
    "\n",
    "    #Family: metrics\n",
    "    fam_loss = hamming_loss(family, pred_family_ham)\n",
    "    fam_score = 1 - fam_loss\n",
    "    fam_dist = np.sum(family != pred_family_ham)\n",
    "\n",
    "    hamming_loss_family.append(fam_loss)\n",
    "    hamming_score_family.append(fam_score)\n",
    "    hamming_distance_family.append(fam_dist)\n",
    "\n",
    "    #Genus: metrics\n",
    "    gen_loss = hamming_loss(genus, pred_genus_ham)\n",
    "    gen_score = 1 - gen_loss\n",
    "    gen_dist = np.sum(genus != pred_genus_ham)\n",
    "\n",
    "    hamming_loss_genus.append(gen_loss)\n",
    "    hamming_score_genus.append(gen_score)\n",
    "    hamming_distance_genus.append(gen_dist)\n",
    "\n",
    "    #Species: metrics\n",
    "    spec_loss = hamming_loss(species, pred_species_ham)\n",
    "    spec_score = 1 - spec_loss\n",
    "    spec_dist = np.sum(species != pred_species_ham)\n",
    "\n",
    "    hamming_loss_species.append(spec_loss)\n",
    "    hamming_score_species.append(spec_score)\n",
    "    hamming_distance_species.append(spec_dist)\n",
    "\n",
    "##RESULTS\n",
    "print('Family:')\n",
    "print('Hamming Distance: Mean = {:.4f}, Std = {:.4f}'.format(np.mean(hamming_distance_family), np.std(hamming_distance_family)))\n",
    "print('  Hamming Score:    Mean = {:.4f}, Std = {:.4f}'.format(np.mean(hamming_score_family), np.std(hamming_score_family)))\n",
    "print('  Hamming Loss:     Mean = {:.4f}, Std = {:.4f}\\n'.format(np.mean(hamming_loss_family), np.std(hamming_loss_family)))\n",
    "\n",
    "print('Genus:')\n",
    "print('  Hamming Distance: Mean = {:.1f}, Std = {:.1f}'.format(np.mean(hamming_distance_genus), np.std(hamming_distance_genus)))\n",
    "print('  Hamming Score:    Mean = {:.4f}, Std = {:.4f}'.format(np.mean(hamming_score_genus), np.std(hamming_score_genus)))\n",
    "print('  Hamming Loss:     Mean = {:.4f}, Std = {:.4f}\\n'.format(np.mean(hamming_loss_genus), np.std(hamming_loss_genus)))\n",
    "\n",
    "print('Species:')\n",
    "print('  Hamming Distance: Mean = {:.1f}, Std = {:.1f}'.format(np.mean(hamming_distance_species), np.std(hamming_distance_species)))\n",
    "print('  Hamming Score:    Mean = {:.4f}, Std = {:.4f}'.format(np.mean(hamming_score_species), np.std(hamming_score_species)))\n",
    "print('  Hamming Loss:     Mean = {:.4f}, Std = {:.4f}\\n'.format(np.mean(hamming_loss_species), np.std(hamming_loss_species)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERENCES\n",
    "https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html\n",
    "\n",
    "https://scikit-learn.org/0.18/modules/generated/sklearn.metrics.hamming_loss.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/svm/plot_svm_scale_c.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "\n",
    "Copilot: Do I find the best K before running MC simulation? or within the MC simulation? \n",
    "\n",
    "https://stackoverflow.com/questions/17412439/how-to-split-data-into-trainset-and-testset-randomly\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\n",
    "\n",
    "https://www.geeksforgeeks.org/machine-learning/what-is-silhouette-score/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 12.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
